% =========================================================
% Awesome Video World Models with AR Diffusion
% Consolidated BibTeX File
% =========================================================

@article{chen2024diffusion,
  title={Diffusion forcing: Next-token prediction meets full-sequence diffusion},
  author={Chen, Boyuan and Mart{\'\i} Mons{\'o}, Diego and Du, Yilun and Simchowitz, Max and Tedrake, Russ and Sitzmann, Vincent},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={24081--24125},
  year={2024}
}
@article{jin2024pyramidal,
  title={Pyramidal flow matching for efficient video generative modeling},
  author={Jin, Yang and Sun, Zhicheng and Li, Ningyuan and Xu, Kun and Jiang, Hao and Zhuang, Nan and Huang, Quzhe and Song, Yang and Mu, Yadong and Lin, Zhouchen},
  journal={arXiv preprint arXiv:2410.05954},
  year={2024}
}
@article{song2025history,
  title={History-guided video diffusion},
  author={Song, Kiwhan and Chen, Boyuan and Simchowitz, Max and Du, Yilun and Tedrake, Russ and Sitzmann, Vincent},
  journal={arXiv preprint arXiv:2502.06764},
  year={2025}
}
@inproceedings{sun2025ar,
  title={Ar-diffusion: Asynchronous video generation with auto-regressive diffusion},
  author={Sun, Mingzhen and Wang, Weining and Li, Gen and Liu, Jiawei and Sun, Jiahui and Feng, Wanquan and Lao, Shanshan and Zhou, SiYu and He, Qian and Liu, Jing},
  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
  pages={7364--7373},
  year={2025}
}
@article{wu2025pack,
  title={Pack and force your memory: Long-form and consistent video generation},
  author={Wu, Xiaofei and Zhang, Guozhen and Xu, Zhiyong and Zhou, Yuan and Lu, Qinglin and He, Xuming},
  journal={arXiv preprint arXiv:2510.01784},
  year={2025}
}
@article{po2025bagger,
  title={BAgger: Backwards Aggregation for Mitigating Drift in Autoregressive Video Diffusion Models},
  author={Po, Ryan and Chan, Eric Ryan and Chen, Changan and Wetzstein, Gordon},
  journal={arXiv preprint arXiv:2512.12080},
  year={2025}
}
@article{guo2025end,
  title={End-to-end training for autoregressive video diffusion via self-resampling},
  author={Guo, Yuwei and Yang, Ceyuan and He, Hao and Zhao, Yang and Wei, Meng and Yang, Zhenheng and Huang, Weilin and Lin, Dahua},
  journal={arXiv preprint arXiv:2512.15702},
  year={2025}
}
@inproceedings{yin2025slow,
  title={From slow bidirectional to fast autoregressive video diffusion models},
  author={Yin, Tianwei and Zhang, Qiang and Zhang, Richard and Freeman, William T and Durand, Fredo and Shechtman, Eli and Huang, Xun},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={22963--22974},
  year={2025}
}
@article{huang2025self,
  title={Self forcing: Bridging the train-test gap in autoregressive video diffusion},
  author={Huang, Xun and Li, Zhengqi and He, Guande and Zhou, Mingyuan and Shechtman, Eli},
  journal={arXiv preprint arXiv:2506.08009},
  year={2025}
}
@article{zhu2026causal,
  title={Causal Forcing: Autoregressive Diffusion Distillation Done Right for High-Quality Real-Time Interactive Video Generation},
  author={Zhu, Hongzhou and Zhao, Min and He, Guande and Su, Hang and Li, Chongxuan and Zhu, Jun},
  journal={arXiv preprint arXiv:2602.02214},
  year={2026}
}
@article{lin2025autoregressive,
  title={Autoregressive adversarial post-training for real-time interactive video generation},
  author={Lin, Shanchuan and Yang, Ceyuan and He, Hao and Jiang, Jianwen and Ren, Yuxi and Xia, Xin and Zhao, Yang and Xiao, Xuefeng and Jiang, Lu},
  journal={arXiv preprint arXiv:2506.09350},
  year={2025}
}
@article{yang2025towards,
  title={Towards One-step Causal Video Generation via Adversarial Self-Distillation},
  author={Yang, Yongqi and Huang, Huayang and Peng, Xu and Hu, Xiaobin and Luo, Donghao and Zhang, Jiangning and Wang, Chengjie and Wu, Yu},
  journal={arXiv preprint arXiv:2511.01419},
  year={2025}
}
@article{lu2025reward,
  title={Reward forcing: Efficient streaming video generation with rewarded distribution matching distillation},
  author={Lu, Yunhong and Zeng, Yanhong and Li, Haobo and Ouyang, Hao and Wang, Qiuyu and Cheng, Ka Leong and Zhu, Jiapeng and Cao, Hengyuan and Zhang, Zhipeng and Zhu, Xing and others},
  journal={arXiv preprint arXiv:2512.04678},
  year={2025}
}
@article{wang2026worldcompass,
  title={WorldCompass: Reinforcement Learning for Long-Horizon World Models},
  author={Wang, Zehan and Wang, Tengfei and Zhang, Haiyu and Zuo, Xuhui and Wu, Junta and Wang, Haoyuan and Sun, Wenqiang and Wang, Zhenwei and Cao, Chenjie and Zhao, Hengshuang and others},
  journal={arXiv preprint arXiv:2602.09022},
  year={2026}
}
@article{yang2025longlive,
  title={Longlive: Real-time interactive long video generation},
  author={Yang, Shuai and Huang, Wei and Chu, Ruihang and Xiao, Yicheng and Zhao, Yuyang and Wang, Xianbang and Li, Muyang and Xie, Enze and Chen, Yingcong and Lu, Yao and others},
  journal={arXiv preprint arXiv:2509.22622},
  year={2025}
}
@article{liu2025rolling,
  title={Rolling forcing: Autoregressive long video diffusion in real time},
  author={Liu, Kunhao and Hu, Wenbo and Xu, Jiale and Shan, Ying and Lu, Shijian},
  journal={arXiv preprint arXiv:2509.25161},
  year={2025}
}
@article{cui2025self,
  title={Self-forcing++: Towards minute-scale high-quality video generation},
  author={Cui, Justin and Wu, Jie and Li, Ming and Yang, Tao and Li, Xiaojie and Wang, Rui and Bai, Andrew and Ban, Yuanhao and Hsieh, Cho-Jui},
  journal={arXiv preprint arXiv:2510.02283},
  year={2025}
}
@misc{infinite-forcing,
    Author = {Junyi Chen, Zhoujie Fu, Xianglong He},
    Year = {2025},
    Note = {https://github.com/SOTAMak1r/Infinite-Forcing},
    Title = {Infinite-Forcing: Towards Infinite-Long Video Generation}
}
@article{yesiltepe2025infinity,
  title={Infinity-rope: Action-controllable infinite video generation emerges from autoregressive self-rollout},
  author={Yesiltepe, Hidir and Meral, Tuna Han Salih and Akan, Adil Kaan and Oktay, Kaan and Yanardag, Pinar},
  journal={arXiv preprint arXiv:2511.20649},
  year={2025}
}
@article{yi2025deep,
  title={Deep forcing: Training-free long video generation with deep sink and participative compression},
  author={Yi, Jung and Jang, Wooseok and Cho, Paul Hyunbin and Nam, Jisu and Yoon, Heeji and Kim, Seungryong},
  journal={arXiv preprint arXiv:2512.05081},
  year={2025}
}
@article{li2026train,
  title={Train Short, Inference Long: Training-free Horizon Extension for Autoregressive Video Generation},
  author={Li, Jia and Fu, Xiaomeng and Peng, Xurui and Chen, Weifeng and Zheng, Youwei and Zhao, Tianyu and Wang, Jiexi and Chen, Fangmin and Wang, Xing and So, Hayden Kwok-Hay},
  journal={arXiv preprint arXiv:2602.14027},
  year={2026}
}
@article{xiao2025worldmem,
  title={Worldmem: Long-term consistent world simulation with memory},
  author={Xiao, Zeqi and Lan, Yushi and Zhou, Yifan and Ouyang, Wenqi and Yang, Shuai and Zeng, Yanhong and Pan, Xingang},
  journal={arXiv preprint arXiv:2504.12369},
  year={2025}
}
@article{chen2025learning,
  title={Learning world models for interactive video generation},
  author={Chen, Taiye and Hu, Xun and Ding, Zihan and Jin, Chi},
  journal={arXiv preprint arXiv:2505.21996},
  year={2025}
}
@inproceedings{yu2025context,
  title={Context as memory: Scene-consistent interactive long video generation with memory retrieval},
  author={Yu, Jiwen and Bai, Jianhong and Qin, Yiran and Liu, Quande and Wang, Xintao and Wan, Pengfei and Zhang, Di and Liu, Xihui},
  booktitle={Proceedings of the SIGGRAPH Asia 2025 Conference Papers},
  pages={1--11},
  year={2025}
}
@article{huang2025memory,
  title={Memory forcing: Spatio-temporal memory for consistent scene generation on minecraft},
  author={Huang, Junchao and Hu, Xinting and Han, Boyao and Shi, Shaoshuai and Tian, Zhuotao and He, Tianyu and Jiang, Li},
  journal={arXiv preprint arXiv:2510.03198},
  year={2025}
}
@article{ji2025memflow,
  title={Memflow: Flowing adaptive memory for consistent and efficient long video narratives},
  author={Ji, Sihui and Chen, Xi and Yang, Shuai and Tao, Xin and Wan, Pengfei and Zhao, Hengshuang},
  journal={arXiv preprint arXiv:2512.14699},
  year={2025}
}
@article{yang2026stableworld,
  title={StableWorld: Towards Stable and Consistent Long Interactive Video Generation},
  author={Yang, Ying and Lv, Zhengyao and Pan, Tianlin and Wang, Haofan and Yang, Binxin and Yin, Hubery and Li, Chen and Liu, Ziwei and Si, Chenyang},
  journal={arXiv preprint arXiv:2601.15281},
  year={2026}
}
@article{huang2026live,
  title={LIVE: Long-horizon Interactive Video World Modeling},
  author={Huang, Junchao and Ye, Ziyang and Hu, Xinting and He, Tianyu and Zhang, Guiyu and Shi, Shaoshuai and Bian, Jiang and Jiang, Li},
  journal={arXiv preprint arXiv:2602.03747},
  year={2026}
}
@article{wu2026infinite,
  title={Infinite-World: Scaling Interactive World Models to 1000-Frame Horizons via Pose-Free Hierarchical Memory},
  author={Wu, Ruiqi and He, Xuanhua and Cheng, Meng and Yang, Tianyu and Zhang, Yong and Kang, Zhuoliang and Cai, Xunliang and Wei, Xiaoming and Guo, Chunle and Li, Chongyi and others},
  journal={arXiv preprint arXiv:2602.02393},
  year={2026}
}
@article{chen2026context,
  title={Context Forcing: Consistent Autoregressive Video Generation with Long Context},
  author={Chen, Shuo and Wei, Cong and Sun, Sun and Nie, Ping and Zhou, Kai and Zhang, Ge and Yang, Ming-Hsuan and Chen, Wenhu},
  journal={arXiv preprint arXiv:2602.06028},
  year={2026}
}
@article{xiang2026geometry,
  title={Geometry-Aware Rotary Position Embedding for Consistent Video World Model},
  author={Xiang, Chendong and Liu, Jiajun and Zhang, Jintao and Yang, Xiao and Fang, Zhengwei and Wang, Shizun and Wang, Zijun and Zou, Yingtian and Su, Hang and Zhu, Jun},
  journal={arXiv preprint arXiv:2602.07854},
  year={2026}
}
@article{chen2025skyreels,
  title={Skyreels-v2: Infinite-length film generative model},
  author={Chen, Guibin and Lin, Dixuan and Yang, Jiangping and Lin, Chunze and Zhu, Junchen and Fan, Mingyuan and Zhang, Hao and Chen, Sheng and Chen, Zheng and Ma, Chengcheng and others},
  journal={arXiv preprint arXiv:2504.13074},
  year={2025}
}
@article{teng2025magi,
  title={Magi-1: Autoregressive video generation at scale},
  author={Teng, Hansi and Jia, Hongyu and Sun, Lei and Li, Lingzhi and Li, Maolin and Tang, Mingqiu and Han, Shuai and Zhang, Tianning and Zhang, WQ and Luo, Weifeng and others},
  journal={arXiv preprint arXiv:2505.13211},
  year={2025}
}
@inproceedings{bruce2024genie,
  title={Genie: Generative interactive environments},
  author={Bruce, Jake and Dennis, Michael D and Edwards, Ashley and Parker-Holder, Jack and Shi, Yuge and Hughes, Edward and Lai, Matthew and Mavalankar, Aditi and Steigerwald, Richie and Apps, Chris and others},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}
@article{ye2025yan,
  title={Yan: Foundational interactive video generation},
  author={Ye, Deheng and Zhou, Fangyun and Lv, Jiacheng and Ma, Jianqi and Zhang, Jun and Lv, Junyan and Li, Junyou and Deng, Minwen and Yang, Mingyu and Fu, Qiang and others},
  journal={arXiv preprint arXiv:2508.08601},
  year={2025}
}
@article{he2025matrix,
  title={Matrix-game 2.0: An open-source real-time and streaming interactive world model},
  author={He, Xianglong and Peng, Chunli and Liu, Zexiang and Wang, Boyang and Zhang, Yifan and Cui, Qi and Kang, Fei and Jiang, Biao and An, Mengyin and Ren, Yangyang and others},
  journal={arXiv preprint arXiv:2508.13009},
  year={2025}
}
@article{xiang2025pan,
  title={Pan: A world model for general, interactable, and long-horizon world simulation},
  author={Xiang, Jiannan and Gu, Yi and Liu, Zihan and Feng, Zeyu and Gao, Qiyue and Hu, Yiyan and Huang, Benhao and Liu, Guangyi and Yang, Yichi and Zhou, Kun and others},
  journal={arXiv preprint arXiv:2511.09057},
  year={2025}
}
@article{hong2025relic,
  title={Relic: Interactive video world model with long-horizon memory},
  author={Hong, Yicong and Mei, Yiqun and Ge, Chongjian and Xu, Yiran and Zhou, Yang and Bi, Sai and Hold-Geoffroy, Yannick and Roberts, Mike and Fisher, Matthew and Shechtman, Eli and others},
  journal={arXiv preprint arXiv:2512.04040},
  year={2025}
}
@article{sun2025worldplay,
  title={Worldplay: Towards long-term geometric consistency for real-time interactive world modeling},
  author={Sun, Wenqiang and Zhang, Haiyu and Wang, Haoyuan and Wu, Junta and Wang, Zehan and Wang, Zhenwei and Wang, Yunhong and Zhang, Jun and Wang, Tengfei and Guo, Chunchao},
  journal={arXiv preprint arXiv:2512.14614},
  year={2025}
}
@article{mao2025yume,
  title={Yume-1.5: A Text-Controlled Interactive World Generation Model},
  author={Mao, Xiaofeng and Li, Zhen and Li, Chuanhao and Xu, Xiaojie and Ying, Kaining and He, Tong and Pang, Jiangmiao and Qiao, Yu and Zhang, Kaipeng},
  journal={arXiv preprint arXiv:2512.22096},
  year={2025}
}
@article{team2026advancing,
  title={Advancing Open-source World Models},
  author={Team, Robbyant and Gao, Zelin and Wang, Qiuyu and Zeng, Yanhong and Zhu, Jiapeng and Cheng, Ka Leong and Li, Yixuan and Wang, Hanlin and Xu, Yinghao and Ma, Shuailei and others},
  journal={arXiv preprint arXiv:2601.20540},
  year={2026}
}
@article{shin2025motionstream,
  title={Motionstream: Real-time video generation with interactive motion controls},
  author={Shin, Joonghyuk and Li, Zhengqi and Zhang, Richard and Zhu, Jun-Yan and Park, Jaesik and Shechtman, Eli and Huang, Xun},
  journal={arXiv preprint arXiv:2511.01266},
  year={2025}
}
@article{huang2025live,
  title={Live avatar: Streaming real-time audio-driven avatar generation with infinite length},
  author={Huang, Yubo and Guo, Hailong and Wu, Fangtai and Zhang, Shifeng and Huang, Shijie and Gan, Qijun and Liu, Lin and Zhao, Sirui and Chen, Enhong and Liu, Jiaming and others},
  journal={arXiv preprint arXiv:2512.04677},
  year={2025}
}
@article{shen2025soulx,
  title={SoulX-LiveTalk Technical Report},
  author={Shen, Le and Qian, Qiao and Yu, Tan and Zhou, Ke and Yu, Tianhang and Zhan, Yu and Wang, Zhenjie and Tao, Ming and Yin, Shunshun and Liu, Siyuan},
  journal={arXiv preprint arXiv:2512.23379},
  year={2025}
}
@article{chern2025livetalk,
  title={LiveTalk: Real-Time Multimodal Interactive Video Diffusion via Improved On-Policy Distillation},
  author={Chern, Ethan and Hu, Zhulin and Tang, Bohao and Su, Jiadi and Chern, Steffi and Deng, Zhijie and Liu, Pengfei},
  journal={arXiv preprint arXiv:2512.23576},
  year={2025}
}
@article{ki2026avatar,
  title={Avatar Forcing: Real-Time Interactive Head Avatar Generation for Natural Conversation},
  author={Ki, Taekyung and Jang, Sangwon and Jo, Jaehyeong and Yoon, Jaehong and Hwang, Sung Ju},
  journal={arXiv preprint arXiv:2601.00664},
  year={2026}
}
@article{wang2026hand2world,
  title={Hand2World: Autoregressive Egocentric Interaction Generation via Free-Space Hand Gestures},
  author={Wang, Yuxi and Ouyang, Wenqi and Wei, Tianyi and Dong, Yi and Shen, Zhiqi and Pan, Xingang},
  journal={arXiv preprint arXiv:2602.09600},
  year={2026}
}
@article{guo2026efficient,
  title={Efficient Autoregressive Video Diffusion with Dummy Head},
  author={Guo, Hang and Jia, Zhaoyang and Li, Jiahao and Li, Bin and Cai, Yuanhao and Wang, Jiangshan and Li, Yawei and Lu, Yan},
  journal={arXiv preprint arXiv:2601.20499},
  year={2026}
}
@article{lv2026light,
  title={Light Forcing: Accelerating Autoregressive Video Diffusion via Sparse Attention},
  author={Lv, Chengtao and Shi, Yumeng and Huang, Yushi and Gong, Ruihao and Ren, Shen and Wang, Wenya},
  journal={arXiv preprint arXiv:2602.04789},
  year={2026}
}
@article{samuel2026fast,
  title={Fast Autoregressive Video Diffusion and World Models with Temporal Cache Compression and Sparse Attention},
  author={Samuel, Dvir and Tzachor, Issar and Levy, Matan and Green, Micahel and Chechik, Gal and Ben-Ari, Rami},
  journal={arXiv preprint arXiv:2602.01801},
  year={2026}
}
@article{shaulov2026tokentrim,
  title={TokenTrim: Inference-Time Token Pruning for Autoregressive Long Video Generation},
  author={Shaulov, Ariel and Shaar, Eitan and Edenzon, Amit and Wolf, Lior},
  journal={arXiv preprint arXiv:2602.00268},
  year={2026}
}
@article{chen2026past,
  title={Past-and Future-Informed KV Cache Policy with Salience Estimation in Autoregressive Video Diffusion},
  author={Chen, Hanmo and Xu, Chenghao and Yang, Xu and Chen, Xuan and Deng, Cheng},
  journal={arXiv preprint arXiv:2601.21896},
  year={2026}
}
@article{agarwal2026monarchrt,
  title={MonarchRT: Efficient Attention for Real-Time Video Generation},
  author={Agarwal, Krish and Chen, Zhuoming and Luo, Cheng and Chen, Yongqi and Zheng, Haizhong and Huang, Xun and Rudra, Atri and Chen, Beidi},
  journal={arXiv preprint arXiv:2602.12271},
  year={2026}
}
@article{bai2026causality,
  title={Causality in Video Diffusers is Separable from Denoising},
  author={Bai, Xingjian and He, Guande and Li, Zhengqi and Shechtman, Eli and Huang, Xun and Wu, Zongze},
  journal={arXiv preprint arXiv:2602.10095},
  year={2026}
}
@article{ma2026flow,
  title={Flow caching for autoregressive video generation},
  author={Ma, Yuexiao and Zheng, Xuzhe and Xu, Jing and Xu, Xiwei and Ling, Feng and Zheng, Xiawu and Kuang, Huafeng and Li, Huixia and Wang, Xing and Xiao, Xuefeng and others},
  journal={arXiv preprint arXiv:2602.10825},
  year={2026}
}
@article{xi2026quant,
  title={Quant VideoGen: Auto-Regressive Long Video Generation via 2-Bit KV-Cache Quantization},
  author={Xi, Haocheng and Yang, Shuo and Zhao, Yilong and Li, Muyang and Cai, Han and Li, Xingyang and Lin, Yujun and Zhang, Zhuoyang and Zhang, Jintao and Li, Xiuyu and others},
  journal={arXiv preprint arXiv:2602.02958},
  year={2026}
}
@article{jiang2026olaf,
  title={Olaf-World: Orienting Latent Actions for Video World Modeling},
  author={Jiang, Yuxin and Gu, Yuchao and Tsang, Ivor W and Shou, Mike Zheng},
  journal={arXiv preprint arXiv:2602.10104},
  year={2026}
}
@article{ye2026world,
  title={World Action Models are Zero-shot Policies},
  author={Ye, Seonghyeon and Ge, Yunhao and Zheng, Kaiyuan and Gao, Shenyuan and Yu, Sihyun and Kurian, George and Indupuru, Suneel and Tan, You Liang and Zhu, Chuning and Xiang, Jiannan and others},
  journal={arXiv preprint arXiv:2602.15922},
  year={2026}
}
@article{feng2025vidarc,
  title={Vidarc: Embodied Video Diffusion Model for Closed-loop Control},
  author={Feng, Yao and Xiang, Chendong and Mao, Xinyi and Tan, Hengkai and Zhang, Zuyue and Huang, Shuhe and Zheng, Kaiwen and Liu, Haitian and Su, Hang and Zhu, Jun},
  journal={arXiv preprint arXiv:2512.17661},
  year={2025}
}
@article{xie2026generated,
  title={Generated Reality: Human-centric World Simulation using Interactive Video Generation with Hand and Camera Control},
  author={Xie, Linxi and Sun, Lisong C and Neall, Ashley and Wu, Tong and Cai, Shengqu and Wetzstein, Gordon},
  journal={arXiv preprint arXiv:2602.18422},
  year={2026}
}
